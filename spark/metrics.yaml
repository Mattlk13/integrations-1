# This file was generated in the Smart Agent repo and copied here, DO NOT EDIT HERE.

counter.HiveExternalCatalog.fileCacheHits:
  brief: Total number of file level cache hits occurred
  custom: true
  description: Total number of file level cache hits occurred
  metric_type: counter
  monitor: collectd/spark
  title: counter.HiveExternalCatalog.fileCacheHits

counter.HiveExternalCatalog.filesDiscovered:
  brief: Total number of files discovered
  custom: true
  description: Total number of files discovered
  metric_type: counter
  monitor: collectd/spark
  title: counter.HiveExternalCatalog.filesDiscovered

counter.HiveExternalCatalog.hiveClientCalls:
  brief: Total number of client calls sent to Hive for query processing
  custom: true
  description: Total number of client calls sent to Hive for query processing
  metric_type: counter
  monitor: collectd/spark
  title: counter.HiveExternalCatalog.hiveClientCalls

counter.HiveExternalCatalog.parallelListingJobCount:
  brief: Total number of Hive-specific jobs running in parallel
  custom: true
  description: Total number of Hive-specific jobs running in parallel
  metric_type: counter
  monitor: collectd/spark
  title: counter.HiveExternalCatalog.parallelListingJobCount

counter.HiveExternalCatalog.partitionsFetched:
  brief: Total number of partitions fetched
  custom: true
  description: Total number of partitions fetched
  metric_type: counter
  monitor: collectd/spark
  title: counter.HiveExternalCatalog.partitionsFetched

counter.spark.driver.completed_tasks:
  brief: Total number of completed tasks in driver mapped to a particular application
  custom: true
  description: Total number of completed tasks in driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.completed_tasks

counter.spark.driver.disk_used:
  brief: Amount of disk used by driver mapped to a particular application
  custom: false
  description: Amount of disk used by driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.disk_used

counter.spark.driver.failed_tasks:
  brief: Total number of failed tasks in driver mapped to a particular application
  custom: true
  description: Total number of failed tasks in driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.failed_tasks

counter.spark.driver.memory_used:
  brief: Amount of memory used by driver mapped to a particular application
  custom: false
  description: Amount of memory used by driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.memory_used

counter.spark.driver.total_duration:
  brief: Fraction of time spent by driver mapped to a particular application
  custom: true
  description: Fraction of time spent by driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.total_duration

counter.spark.driver.total_input_bytes:
  brief: Number of input bytes in driver mapped to a particular application
  custom: false
  description: Number of input bytes in driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.total_input_bytes

counter.spark.driver.total_shuffle_read:
  brief: Size read during a shuffle in driver mapped to a particular application
  custom: false
  description: Size read during a shuffle in driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.total_shuffle_read

counter.spark.driver.total_shuffle_write:
  brief: Size written to during a shuffle in driver mapped to a particular application
  custom: false
  description: Size written to during a shuffle in driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.total_shuffle_write

counter.spark.driver.total_tasks:
  brief: Total number of tasks in driver mapped to a particular application
  custom: false
  description: Total number of tasks in driver mapped to a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.driver.total_tasks

counter.spark.executor.completed_tasks:
  brief: Completed tasks across executors working for a particular application
  custom: true
  description: Completed tasks across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.completed_tasks

counter.spark.executor.disk_used:
  brief: Amount of disk used across executors working for a particular application
  custom: false
  description: Amount of disk used across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.disk_used

counter.spark.executor.failed_tasks:
  brief: Failed tasks across executors working for a particular application
  custom: true
  description: Failed tasks across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.failed_tasks

counter.spark.executor.memory_used:
  brief: Amount of memory used across executors working for a particular application
  custom: false
  description: Amount of memory used across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.memory_used

counter.spark.executor.total_duration:
  brief: Fraction of time spent across executors working for a particular application
  custom: true
  description: Fraction of time spent across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.total_duration

counter.spark.executor.total_input_bytes:
  brief: Number of input bytes across executors working for a particular application
  custom: false
  description: Number of input bytes across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.total_input_bytes

counter.spark.executor.total_shuffle_read:
  brief: Size read during a shuffle in a particular application's executors
  custom: false
  description: Size read during a shuffle in a particular application's executors
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.total_shuffle_read

counter.spark.executor.total_shuffle_write:
  brief: Size written to during a shuffle in a particular application's executors
  custom: false
  description: Size written to during a shuffle in a particular application's executors
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.total_shuffle_write

counter.spark.executor.total_tasks:
  brief: Total tasks across executors working for a particular application
  custom: true
  description: Total tasks across executors working for a particular application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.executor.total_tasks

counter.spark.streaming.num_processed_records:
  brief: Number of processed records in a streaming application
  custom: false
  description: Number of processed records in a streaming application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.streaming.num_processed_records

counter.spark.streaming.num_received_records:
  brief: Number of received records in a streaming application
  custom: false
  description: Number of received records in a streaming application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.streaming.num_received_records

counter.spark.streaming.num_total_completed_batches:
  brief: Number of batches completed in a streaming application
  custom: false
  description: Number of batches completed in a streaming application
  metric_type: counter
  monitor: collectd/spark
  title: counter.spark.streaming.num_total_completed_batches

gauge.jvm.MarkSweepCompact.count:
  brief: Garbage collection count
  custom: true
  description: Garbage collection count
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.MarkSweepCompact.count

gauge.jvm.MarkSweepCompact.time:
  brief: Garbage collection time
  custom: true
  description: Garbage collection time
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.MarkSweepCompact.time

gauge.jvm.heap.committed:
  brief: Amount of committed heap memory (in MB)
  custom: false
  description: Amount of committed heap memory (in MB)
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.heap.committed

gauge.jvm.heap.used:
  brief: Amount of used heap memory (in MB)
  custom: false
  description: Amount of used heap memory (in MB)
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.heap.used

gauge.jvm.non-heap.committed:
  brief: Amount of committed non-heap memory (in MB)
  custom: false
  description: Amount of committed non-heap memory (in MB)
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.non-heap.committed

gauge.jvm.non-heap.used:
  brief: Amount of used non-heap memory (in MB)
  custom: false
  description: Amount of used non-heap memory (in MB)
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.non-heap.used

gauge.jvm.pools.Code-Cache.committed:
  brief: Amount of memory committed for compilation and storage of native code
  custom: true
  description: Amount of memory committed for compilation and storage of native code
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Code-Cache.committed

gauge.jvm.pools.Code-Cache.used:
  brief: Amount of memory used to compile and store native code
  custom: true
  description: Amount of memory used to compile and store native code
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Code-Cache.used

gauge.jvm.pools.Compressed-Class-Space.committed:
  brief: Amount of memory committed for compressing a class object
  custom: true
  description: Amount of memory committed for compressing a class object
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Compressed-Class-Space.committed

gauge.jvm.pools.Compressed-Class-Space.used:
  brief: Amount of memory used to compress a class object
  custom: true
  description: Amount of memory used to compress a class object
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Compressed-Class-Space.used

gauge.jvm.pools.Eden-Space.committed:
  brief: Amount of memory committed for the initial allocation of objects
  custom: true
  description: Amount of memory committed for the initial allocation of objects
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Eden-Space.committed

gauge.jvm.pools.Eden-Space.used:
  brief: Amount of memory used for the initial allocation of objects
  custom: true
  description: Amount of memory used for the initial allocation of objects
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Eden-Space.used

gauge.jvm.pools.Metaspace.committed:
  brief: Amount of memory committed for storing classes and classloaders
  custom: true
  description: Amount of memory committed for storing classes and classloaders
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Metaspace.committed

gauge.jvm.pools.Metaspace.used:
  brief: Amount of memory used to store classes and classloaders
  custom: true
  description: Amount of memory used to store classes and classloaders
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Metaspace.used

gauge.jvm.pools.Survivor-Space.committed:
  brief: Amount of memory committed specifically for objects that have survived GC
    of the Eden Space
  custom: true
  description: Amount of memory committed specifically for objects that have survived
    GC of the Eden Space
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Survivor-Space.committed

gauge.jvm.pools.Survivor-Space.used:
  brief: Amount of memory used for objects that have survived GC of the Eden Space
  custom: true
  description: Amount of memory used for objects that have survived GC of the Eden
    Space
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Survivor-Space.used

gauge.jvm.pools.Tenured-Gen.committed:
  brief: Amount of memory committed to store objects that have lived in the survivor
    space for a given period of time
  custom: true
  description: Amount of memory committed to store objects that have lived in the
    survivor space for a given period of time
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Tenured-Gen.committed

gauge.jvm.pools.Tenured-Gen.used:
  brief: Amount of memory used for objects that have lived in the survivor space for
    a given period of time
  custom: true
  description: Amount of memory used for objects that have lived in the survivor space
    for a given period of time
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.pools.Tenured-Gen.used

gauge.jvm.total.committed:
  brief: Amount of committed JVM memory (in MB)
  custom: false
  description: Amount of committed JVM memory (in MB)
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.total.committed

gauge.jvm.total.used:
  brief: Amount of used JVM memory (in MB)
  custom: false
  description: Amount of used JVM memory (in MB)
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.jvm.total.used

gauge.master.aliveWorkers:
  brief: Total functioning workers
  custom: false
  description: Total functioning workers
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.master.aliveWorkers

gauge.master.apps:
  brief: Total number of active applications in the spark cluster
  custom: false
  description: Total number of active applications in the spark cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.master.apps

gauge.master.waitingApps:
  brief: Total number of waiting applications in the spark cluster
  custom: false
  description: Total number of waiting applications in the spark cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.master.waitingApps

gauge.master.workers:
  brief: Total number of workers in spark cluster
  custom: false
  description: Total number of workers in spark cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.master.workers

gauge.spark.driver.active_tasks:
  brief: Total number of active tasks in driver mapped to a particular application
  custom: true
  description: Total number of active tasks in driver mapped to a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.driver.active_tasks

gauge.spark.driver.max_memory:
  brief: Maximum memory used by driver mapped to a particular application
  custom: false
  description: Maximum memory used by driver mapped to a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.driver.max_memory

gauge.spark.driver.rdd_blocks:
  brief: Number of RDD blocks in the driver mapped to a particular application
  custom: true
  description: Number of RDD blocks in the driver mapped to a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.driver.rdd_blocks

gauge.spark.executor.active_tasks:
  brief: Total number of active tasks across all executors working for a particular
    application
  custom: true
  description: Total number of active tasks across all executors working for a particular
    application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.executor.active_tasks

gauge.spark.executor.count:
  brief: Total number of executors performing for an active application in the spark
    cluster
  custom: false
  description: Total number of executors performing for an active application in the
    spark cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.executor.count

gauge.spark.executor.max_memory:
  brief: Max memory across all executors working for a particular application
  custom: false
  description: Max memory across all executors working for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.executor.max_memory

gauge.spark.executor.rdd_blocks:
  brief: Number of RDD blocks across all executors working for a particular application
  custom: true
  description: Number of RDD blocks across all executors working for a particular
    application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.executor.rdd_blocks

gauge.spark.job.num_active_stages:
  brief: Total number of active stages for an active application in the spark cluster
  custom: false
  description: Total number of active stages for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_active_stages

gauge.spark.job.num_active_tasks:
  brief: Total number of active tasks for an active application in the spark cluster
  custom: false
  description: Total number of active tasks for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_active_tasks

gauge.spark.job.num_completed_stages:
  brief: Total number of completed stages for an active application in the spark cluster
  custom: false
  description: Total number of completed stages for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_completed_stages

gauge.spark.job.num_completed_tasks:
  brief: Total number of completed tasks for an active application in the spark cluster
  custom: false
  description: Total number of completed tasks for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_completed_tasks

gauge.spark.job.num_failed_stages:
  brief: Total number of failed stages for an active application in the spark cluster
  custom: false
  description: Total number of failed stages for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_failed_stages

gauge.spark.job.num_failed_tasks:
  brief: Total number of failed tasks for an active application in the spark cluster
  custom: false
  description: Total number of failed tasks for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_failed_tasks

gauge.spark.job.num_skipped_stages:
  brief: Total number of skipped stages for an active application in the spark cluster
  custom: false
  description: Total number of skipped stages for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_skipped_stages

gauge.spark.job.num_skipped_tasks:
  brief: Total number of skipped tasks for an active application in the spark cluster
  custom: false
  description: Total number of skipped tasks for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_skipped_tasks

gauge.spark.job.num_tasks:
  brief: Total number of tasks for an active application in the spark cluster
  custom: false
  description: Total number of tasks for an active application in the spark cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.job.num_tasks

gauge.spark.num_active_stages:
  brief: Total number of active stages for an active application in the spark cluster
  custom: false
  description: Total number of active stages for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.num_active_stages

gauge.spark.num_running_jobs:
  brief: Total number of running jobs for an active application in the spark cluster
  custom: false
  description: Total number of running jobs for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.num_running_jobs

gauge.spark.stage.disk_bytes_spilled:
  brief: Actual size written to disk for an active application in the spark cluster
  custom: false
  description: Actual size written to disk for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.disk_bytes_spilled

gauge.spark.stage.executor_run_time:
  brief: Fraction of time spent by (and averaged across) executors for a particular
    application
  custom: false
  description: Fraction of time spent by (and averaged across) executors for a particular
    application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.executor_run_time

gauge.spark.stage.input_bytes:
  brief: Input size for a particular application
  custom: false
  description: Input size for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.input_bytes

gauge.spark.stage.input_records:
  brief: Input records received for a particular application
  custom: false
  description: Input records received for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.input_records

gauge.spark.stage.memory_bytes_spilled:
  brief: Size spilled to disk from memory for an active application in the spark cluster
  custom: false
  description: Size spilled to disk from memory for an active application in the spark
    cluster
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.memory_bytes_spilled

gauge.spark.stage.output_bytes:
  brief: Output size for a particular application
  custom: false
  description: Output size for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.output_bytes

gauge.spark.stage.output_records:
  brief: Output records written to for a particular application
  custom: false
  description: Output records written to for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.output_records

gauge.spark.stage.shuffle_read_bytes:
  brief: Read size during shuffle phase for a particular application
  custom: true
  description: Read size during shuffle phase for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.shuffle_read_bytes

gauge.spark.stage.shuffle_read_records:
  brief: Number of records read during shuffle phase for a particular application
  custom: true
  description: Number of records read during shuffle phase for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.shuffle_read_records

gauge.spark.stage.shuffle_write_bytes:
  brief: Size written during shuffle phase for a particular application
  custom: true
  description: Size written during shuffle phase for a particular application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.shuffle_write_bytes

gauge.spark.stage.shuffle_write_records:
  brief: Number of records written to during shuffle phase for a particular application
  custom: true
  description: Number of records written to during shuffle phase for a particular
    application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.stage.shuffle_write_records

gauge.spark.streaming.avg_input_rate:
  brief: Average input rate of records across retained batches in a streaming application
  custom: false
  description: Average input rate of records across retained batches in a streaming
    application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.streaming.avg_input_rate

gauge.spark.streaming.avg_processing_time:
  brief: Average processing time in a streaming application
  custom: false
  description: Average processing time in a streaming application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.streaming.avg_processing_time

gauge.spark.streaming.avg_scheduling_delay:
  brief: Average scheduling delay in a streaming application
  custom: false
  description: Average scheduling delay in a streaming application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.streaming.avg_scheduling_delay

gauge.spark.streaming.avg_total_delay:
  brief: Average total delay in a streaming application
  custom: false
  description: Average total delay in a streaming application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.streaming.avg_total_delay

gauge.spark.streaming.num_active_batches:
  brief: Number of active batches in a streaming application
  custom: false
  description: Number of active batches in a streaming application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.streaming.num_active_batches

gauge.spark.streaming.num_inactive_receivers:
  brief: Number of inactive receivers in a streaming application
  custom: false
  description: Number of inactive receivers in a streaming application
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.spark.streaming.num_inactive_receivers

gauge.worker.coresFree:
  brief: Total cores free for a particular worker process
  custom: false
  description: Total cores free for a particular worker process
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.worker.coresFree

gauge.worker.coresUsed:
  brief: Total cores used by a particular worker process
  custom: false
  description: Total cores used by a particular worker process
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.worker.coresUsed

gauge.worker.executors:
  brief: Total number of executors for a particular worker process
  custom: false
  description: Total number of executors for a particular worker process
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.worker.executors

gauge.worker.memFree_MB:
  brief: Total memory free for a particular worker process
  custom: false
  description: Total memory free for a particular worker process
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.worker.memFree_MB

gauge.worker.memUsed_MB:
  brief: Memory used by a particular worker process
  custom: false
  description: Memory used by a particular worker process
  metric_type: gauge
  monitor: collectd/spark
  title: gauge.worker.memUsed_MB

